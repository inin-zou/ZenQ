{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Quantum convolutional neural network for Perceval"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa8f73d6f5d5d550"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from scipy.special import binom\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import combinations\n",
    "from scipy.special import comb\n",
    "from itertools import combinations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T16:28:07.282333Z",
     "start_time": "2025-01-12T16:28:07.279262Z"
    }
   },
   "id": "a63974a4d5b8e18d"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def BSH_Unitary(nbr_state, gate_impact, device):\n",
    "    \"\"\" Return an BSH corresponding unitary decomposed as coeffs that should be multiplied by\n",
    "    cos(theta), coeffs that should be multiplied by sin(theta) and the ones that are constant\n",
    "    equal to one. This decomposition allows to avoid inplace operations. \n",
    "    Args:\n",
    "        - nbr_state: size of the considered basis\n",
    "        - gate impact: list of tuples of basis vectors. Their planar rotation satisfies \n",
    "        this transformation\n",
    "        - device: torch device (cpu, cuda, etc...)\n",
    "    \"\"\"\n",
    "    cos_matrix = torch.zeros((nbr_state,nbr_state), dtype=torch.float32, device=device)\n",
    "    sin_matrix = torch.zeros((nbr_state,nbr_state), dtype=torch.float32, device=device)\n",
    "    id_matrix = torch.eye(nbr_state, dtype=torch.uint8, device=device)\n",
    "    for tuple_states in gate_impact:\n",
    "        i,j = tuple_states\n",
    "        id_matrix[i,i] = 0\n",
    "        id_matrix[j,j] = 0\n",
    "        cos_matrix[i,i] = 1\n",
    "        cos_matrix[j,j] = -1\n",
    "        sin_matrix[i,j] = 1\n",
    "        sin_matrix[j,i] = 1\n",
    "    return(cos_matrix, sin_matrix, id_matrix)\n",
    "\n",
    "\n",
    "def recursive_next_list_BSH(n, k, list_index, index):\n",
    "    new_list_index = list_index.copy()\n",
    "    new_list_index[index] += 1\n",
    "    if (new_list_index[index] // n > 0):\n",
    "        new_list_index = recursive_next_list_BSH(n - 1, k, new_list_index, index - 1)\n",
    "        new_list_index[index] = new_list_index[index - 1] + 1\n",
    "    return (new_list_index)\n",
    "\n",
    "\n",
    "def dictionary_BSH(n, k):\n",
    "    \"\"\" gives a dictionary that links the state and the list of active bits\n",
    "    for a k arrangment basis \"\"\"\n",
    "    nbr_of_states = int(binom(n, k))\n",
    "    BSH_dictionary = {}\n",
    "    for state in range(nbr_of_states):\n",
    "        if (state == 0):\n",
    "            BSH_dictionary[state] = [i for i in range(k)]\n",
    "        else:\n",
    "            BSH_dictionary[state] = recursive_next_list_BSH(n, k, BSH_dictionary[state - 1], k - 1)\n",
    "    return (BSH_dictionary)\n",
    "\n",
    "\n",
    "def map_BSH(n, k):\n",
    "    \"\"\" Given the number of qubits n and the chosen Hamming weight k, outputs\n",
    "    the corresponding state for a tuple of k active qubits. \"\"\"\n",
    "    Dict_BSH = dictionary_BSH(n, k)\n",
    "    mapping_BSH = {tuple(val): key for (key, val) in Dict_BSH.items()}\n",
    "    return (mapping_BSH)\n",
    "\n",
    "\n",
    "def BSH_generalized(a, b, n, k, mapping_BSH):\n",
    "    \"\"\" Given the two qubits a,b the BSH gate is applied on, it outputs a list of\n",
    "    tuples of basis vectors satisfying this transformation \"\"\"\n",
    "    # Selection of all the affected states\n",
    "    BSH = []\n",
    "    # List of qubits except a and b:\n",
    "    list_qubit = [i for i in range(n)]\n",
    "    list_qubit.pop(max(a, b))\n",
    "    list_qubit.pop(min(a, b))\n",
    "    # We create the list of possible active qubit set for this BSH:\n",
    "    list_combinations = list(combinations(list_qubit, k - 1))\n",
    "    for element in list_combinations:\n",
    "        active_qubits_a = sorted([a] + list(element))\n",
    "        active_qubits_b = sorted([b] + list(element))\n",
    "        BSH.append((mapping_BSH[tuple(active_qubits_a)], mapping_BSH[tuple(active_qubits_b)]))\n",
    "    return BSH\n",
    "\n",
    "\n",
    "def BSH_Unitaries(n, k, list_gates, device):\n",
    "    \"\"\" We store the BSH unitaries corresponding to each edge in the qubit connectivity to\n",
    "    save memory. This allows to different BSH applied on the same pair of qubit to use the\n",
    "    same unitary (but different parameters).\n",
    "    Args:\n",
    "        - n: nbr of qubits\n",
    "        - k: chosen Hamming Weight\n",
    "        - list_gates: list of tuples representing the qubits affected by each BSH\n",
    "        - device: torch device (cpu, cuda, etc...)\n",
    "    Output:\n",
    "        - BSH_Unitaries_dict: a dictionary with key tuples of qubits affected by BSH and\n",
    "        with values tuples of tensors that decompose the equivalent unitary such as in\n",
    "        BSH_Unitary (cos_matrix, sin_matrix, id_matrix)\n",
    "    \"\"\"\n",
    "    BSH_Unitaries_dict, qubit_edges = {}, list(set(list_gates))\n",
    "    mapping_BSH = map_BSH(n, k)\n",
    "    for (i,j) in qubit_edges:\n",
    "        BSH_Unitaries_dict[(i,j)] = BSH_Unitary(int(binom(n,k)), BSH_generalized(i,j,n,k,mapping_BSH), device)\n",
    "    return(BSH_Unitaries_dict)\n",
    "\n",
    "\n",
    "def BSH_generalized_I2_2D(a, b, I):\n",
    "    \"\"\" Given the two qubits a,b the BSH gate is applied on, it outputs a list of\n",
    "    tuples of basis vectors afffected by a rotation in the basis of IxI images. \n",
    "    We suppose that a and b are in the same register (line or column). \"\"\"\n",
    "    # Selection of all the affected states\n",
    "    BSH = []\n",
    "    if (a < I and b < I):\n",
    "        # We are in the line register\n",
    "        for column in range(I):\n",
    "            BSH.append((a * I + column, b * I + column))\n",
    "    elif (a >= I and b >= I):\n",
    "        # We are in the column register\n",
    "        for line in range(I):\n",
    "            BSH.append((line * I + a - I, line * I + b - I))\n",
    "    else:\n",
    "        # We are in the cross register\n",
    "        print(\"Error in BSH_generalized_I2: the two qubits are not in the same register\")\n",
    "    return (BSH)\n",
    "\n",
    "\n",
    "def BSH_Unitaries_I2(I, list_gates, device):\n",
    "    \"\"\" We store the BSH unitaries corresponding to each edge in the qubit connectivity to\n",
    "    save memory. This allows to different BSH applied on the same pair of qubit to use the\n",
    "    same unitary (but different parameters). This function differs from BSH_Unitaries as \n",
    "    we consider the basis of the Image.\n",
    "    Args:\n",
    "        - I: size of the image\n",
    "        - list_gates: list of tuples representing the qubits affected by each BSH\n",
    "        - device: torch device (cpu, cuda, etc...)\n",
    "    Output:\n",
    "        - BSH_Unitaries_dict: a dictionary with key tuples of qubits affected by BSH and\n",
    "        with values tuples of tensors that decompose the equivalen unitary such as in\n",
    "        BSH_Unitary (cos_matrix, sin_matrix, id_matrix)\n",
    "    \"\"\"\n",
    "    BSH_Unitaries_dict, qubit_edges = {}, list(set(list_gates))\n",
    "    for (i,j) in qubit_edges:\n",
    "        BSH_Unitaries_dict[(i,j)] = BSH_Unitary(int(I**2), BSH_generalized_I2_2D(i,j,I), device)\n",
    "    return(BSH_Unitaries_dict)\n",
    "\n",
    "\n",
    "def unitary_matrix(angle, qubit_tuple, BSH_unitaries):\n",
    "    return BSH_unitaries[qubit_tuple][0] * torch.cos(angle) + BSH_unitaries[qubit_tuple][1] * torch.sin(angle) + BSH_unitaries[qubit_tuple][2]\n",
    "\n",
    "\n",
    "def calculate_qfim_and_rank(state_vector, partials):\n",
    "    \"\"\"\n",
    "    QFIM_{i,j} = 4 Re[ <dpsi_i | dpsi_j> - <dpsi_i|psi>*<psi|dpsi_j> ]\n",
    "    where dpsi_i = d|psi>/dtheta_i.\n",
    "\n",
    "    'partials' is a list of d|psi>/dtheta_i. \n",
    "    If you have D parameters, 'partials' has length D.\n",
    "    \"\"\"\n",
    "    # Number of parameters\n",
    "    D = len(partials)\n",
    "\n",
    "    psi = state_vector.to(torch.complex128)\n",
    "    partials = [p.to(torch.complex128) for p in partials]\n",
    "\n",
    "    QFIM = torch.zeros((D, D), dtype=torch.float64, device=psi.device)\n",
    "\n",
    "    # Precompute <psi | dpsi_j>\n",
    "    psi_conj = psi.conj()\n",
    "    overlaps_psi_dpsi = []\n",
    "    for j in range(D):\n",
    "        overlap_j = torch.sum(psi_conj * partials[j])\n",
    "        overlaps_psi_dpsi.append(overlap_j)\n",
    "\n",
    "    for i in range(D):\n",
    "        dpsi_i = partials[i]\n",
    "        dpsi_i_conj = dpsi_i.conj()\n",
    "        overlap_psi_dpsi_i = overlaps_psi_dpsi[i]\n",
    "\n",
    "        for j in range(D):\n",
    "            dpsi_j = partials[j]\n",
    "            overlap_dpsi_i_dpsi_j = torch.sum(dpsi_i_conj * dpsi_j)\n",
    "            overlap_psi_dpsi_j = overlaps_psi_dpsi[j]\n",
    "\n",
    "            # QFIM_{i,j} = 4 Re[ <dpsi_i|dpsi_j> - <dpsi_i|psi>*<psi|dpsi_j> ]\n",
    "            qfim_element = overlap_dpsi_i_dpsi_j - overlap_psi_dpsi_i.conj() * overlap_psi_dpsi_j\n",
    "            QFIM[i, j] = 4.0 * torch.real(qfim_element)\n",
    "\n",
    "    rank = torch.linalg.matrix_rank(QFIM).item()\n",
    "    return QFIM, rank\n",
    "\n",
    "\n",
    "def circuit(dim_state, angles: torch.Tensor, BSH_unitaries) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    angles shape = (#gates,).\n",
    "    Returns the first column of U(angles) as a size-(dk,) state vector.\n",
    "    \"\"\"\n",
    "    U = torch.eye(dim_state, dtype=torch.float32, device=device)\n",
    "    for gate_idx, qubit_tuple in enumerate(list_gates):\n",
    "        U = U @ unitary_matrix(angles[gate_idx], qubit_tuple, BSH_unitaries)\n",
    "\n",
    "    return U[:, 0]  # shape: (dk,)\n",
    "\n",
    "\n",
    "def circuit_diff_HW(angles: torch.Tensor) -> torch.Tensor:\n",
    "    U = torch.eye(dim_state, dtype=torch.float32, device=device)\n",
    "    for gate_idx, qubit_tuple in enumerate(list_gates):\n",
    "        U = U @ unitary_matrix(angles[gate_idx], qubit_tuple, BSH_unitaries)\n",
    "    return U[:, 0]  # shape: (dk,)\n",
    "\n",
    "\n",
    "def get_quantum_loader(number_sample, PCA_data, angles_param, num_epochs, dim_state, BSH_unitaries):\n",
    "    sum_error = 0\n",
    "    psi_s = torch.zeros([number_sample,dim_state])\n",
    "    for sample_idx in range(number_sample):\n",
    "        m_np = PCA_data[sample_idx]         # shape (10,)\n",
    "        m = torch.tensor(m_np, dtype=torch.float32)  # shape (10,)\n",
    "        m = m / (m.norm() + 1e-12)\n",
    "        m = m.to(device)\n",
    "        optimizer = optim.Adam([angles_param], lr=0.01)\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            psi = circuit(dim_state, angles_param, BSH_unitaries)\n",
    "            norm_psi = psi.norm().detach()\n",
    "            if norm_psi.item() > 1e-12:\n",
    "                psi_normed = psi / norm_psi\n",
    "            else:\n",
    "                psi_normed = psi\n",
    "            loss = loss_fn(psi_normed, m)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # Final evaluation\n",
    "        psi_final = circuit(dim_state, angles_param, BSH_unitaries).detach()\n",
    "        psi_final_normed = psi_final / (psi_final.norm() + 1e-12)\n",
    "        # print(psi_final_normed)\n",
    "        # print(m)\n",
    "        final_mse = loss_fn(psi_final_normed, m).item()\n",
    "        sum_error += final_mse\n",
    "\n",
    "        psi_s[sample_idx] = psi_final_normed\n",
    "\n",
    "    return angles_param.data, sum_error/number_sample, psi_s\n",
    "\n",
    "\n",
    "def get_PCA_data(n_components):\n",
    "    transform = transforms.ToTensor()\n",
    "    mnist_train = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    N = 6000  # Typically 60,000\n",
    "    X_list = []\n",
    "    for i in range(N):\n",
    "        img, label = mnist_train[i]  # img is shape (1, 28, 28)\n",
    "        img_np = img.numpy().squeeze()  # shape (28, 28)\n",
    "        flattened = img_np.reshape(-1)  # shape (784,)\n",
    "        X_list.append(flattened)\n",
    "\n",
    "    X = np.array(X_list, dtype=np.float32)  # shape (N, 784), on CPU\n",
    "    pca = PCA(n_components=n_components)\n",
    "    PCA_data = pca.fit_transform(X)  # shape (N, 10)\n",
    "    return PCA_data\n",
    "\n",
    "\n",
    "def preprocess_and_pool(data, output_size, device):\n",
    "    \"\"\"\n",
    "    Preprocess and pool MNIST images using AdaptiveAvgPool2d.\n",
    "    \n",
    "    Args:\n",
    "        data (torch.Tensor): Input data of shape (6000, 784).\n",
    "        output_size (int): Desired output size I for (I, I) pooling.\n",
    "        device (torch.device): Device to perform computation on (e.g., 'cuda' or 'cpu').\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Pooled data of shape (6000, I * I).\n",
    "    \"\"\"\n",
    "    # Ensure the data is in the correct shape for MNIST (6000, 28, 28)\n",
    "    data = data.view(-1, 1, 28, 28)  # Reshape to (6000, 1, 28, 28)\n",
    "\n",
    "    # Define the adaptive average pooling layer\n",
    "    adaptive_avg_pool = nn.AdaptiveAvgPool2d((output_size, output_size))\n",
    "\n",
    "    # Apply pooling\n",
    "    pooled_data = adaptive_avg_pool(data)\n",
    "\n",
    "    # Reshape back to (6000, I * I) if needed\n",
    "    pooled_data = pooled_data.view(-1, output_size * output_size)\n",
    "\n",
    "    # Move the data to the specified device\n",
    "    pooled_data = pooled_data.to(device)\n",
    "\n",
    "    return pooled_data\n",
    "\n",
    "\n",
    "def get_pooling_data(I):\n",
    "    transform = transforms.ToTensor()\n",
    "    mnist_train = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    N = 6000  # Typically 60,000\n",
    "    X_list = []\n",
    "    for i in range(N):\n",
    "        img, label = mnist_train[i]  # img is shape (1, 28, 28)\n",
    "        img_np = img.numpy().squeeze()  # shape (28, 28)\n",
    "        flattened = img_np.reshape(-1)  # shape (784,)\n",
    "        X_list.append(flattened)\n",
    "\n",
    "    X = np.array(X_list, dtype=np.float32)  # shape (N, 784), on CPU\n",
    "    print(X.shape)\n",
    "    return preprocess_and_pool(torch.from_numpy(X), I, device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T16:28:08.757091Z",
     "start_time": "2025-01-12T16:28:08.727566Z"
    }
   },
   "id": "c2e10252e095d842"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate the QFIM rank of a given gate layout\n",
    "corresponds to \"ZenQ_Report.pdf\" 2.3.1 Find a good gate layout"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e52d158b3dd3e9ad"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gates (parameters) = 11 => QFIM is torch.Size([11, 11])\n",
      "Rank of QFIM: 9\n",
      "Maximum QFIM rank: 9\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "k = 2\n",
    "# torch.manual_seed(42)\n",
    "dim_state = (int)(comb(n,k))\n",
    "device = torch.device(\"cpu\")\n",
    "list_gates =  [(0,2),(1,3),(0,1),(2,3),(0,2),(3,4),(1,3),(0,1),(2,3),(3,4),(1,3)]\n",
    "BSH_unitaries = BSH_Unitaries(n, k, list_gates, device)\n",
    "angles_param = nn.Parameter(torch.rand((len(list_gates),), device=device))\n",
    "\n",
    "state_vector = circuit(dim_state, angles_param, BSH_unitaries)  # shape: (dk,)\n",
    "partial_matrix = torch.autograd.functional.jacobian(circuit_diff_HW, angles_param)\n",
    "partials = []\n",
    "for p in range(partial_matrix.shape[1]):\n",
    "    dpsi_p = partial_matrix[:, p]\n",
    "    partials.append(dpsi_p)\n",
    "\n",
    "QFIM, rank = calculate_qfim_and_rank(state_vector, partials)\n",
    "\n",
    "print(f\"Number of gates (parameters) = {len(list_gates)} => QFIM is {QFIM.shape}\")\n",
    "print(\"Rank of QFIM:\", rank)\n",
    "print(\"Maximum QFIM rank:\", dim_state-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T17:38:13.203609Z",
     "start_time": "2025-01-12T17:38:13.178907Z"
    }
   },
   "id": "c90a03edf0d7e314"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate the encoding parameters of a given MNIST image\n",
    "corresponds to \"ZenQ_Report.pdf\" 2.3.2 Circuit implementation\n",
    "the variable \"angles\" is what we want"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7366927c90873"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The averge error 0.013060052460059524 for 10 training dataset samples\n",
      "and we obtain the encoding parameters, size torch.Size([11])\n"
     ]
    }
   ],
   "source": [
    "angles_param = nn.Parameter(torch.rand(len(list_gates), device=device))\n",
    "number_sample = 10\n",
    "num_epochs = 100\n",
    "n_components = dim_state\n",
    "PCA_data = get_PCA_data(n_components)\n",
    "angles, averge_error, psi_final = get_quantum_loader(number_sample, PCA_data, angles_param, num_epochs, dim_state, BSH_unitaries)\n",
    "# print(angles)\n",
    "print(\"The averge error\", averge_error, \"for\", number_sample, \"training dataset samples\")\n",
    "print(\"and we obtain the encoding parameters, size\", angles.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T16:28:18.686227Z",
     "start_time": "2025-01-12T16:28:16.895332Z"
    }
   },
   "id": "ec04f62d5b78358f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
