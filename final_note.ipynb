{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# First part: find encoding angles"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b19073e82cca808a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Flexible_IM_to_HW_Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A module that:\n",
    "      1) Takes an image of shape (B, C, input_size, input_size).\n",
    "      2) Averages it down to (B, C, m, m) via adaptive pooling.\n",
    "      3) Flattens to (B, C*m*m) => 'IM basis' with dimension m^2.\n",
    "      4) Embeds into the HW=2 subspace for 2m qubits => dimension choose(2m,2).\n",
    "         Zeroes for pairs on the same side, IM values for cross-side pairs.\n",
    "         \n",
    "    Args:\n",
    "        input_size (int): The height/width of the input image (e.g., 28 for MNIST).\n",
    "        m (int): The dimension to pool down to (e.g., 10).\n",
    "        in_channels (int): Number of input channels (e.g., 1 for MNIST).\n",
    "        \n",
    "    Example: \n",
    "        For MNIST, you'd typically do:\n",
    "        \n",
    "            encoder = Flexible_IM_to_HW_Encoder(input_size=28, m=10, in_channels=1)\n",
    "            # Then feed a batch of shape (B, 1, 28, 28).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=28, m=10, in_channels=1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.m = m\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        # We'll adaptively pool from (input_size x input_size) to (m x m)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((m, m))\n",
    "\n",
    "        # Dimension of IM basis = m*m\n",
    "        # Dimension of HW=2 subspace for 2m qubits = comb(2m, 2) = (2m)(2m-1)/2\n",
    "        self.hw_dim = (2*m)*(2*m - 1)//2\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (B, in_channels, input_size, input_size)\n",
    "        Returns:\n",
    "            x_hw: Tensor of shape (B, self.hw_dim)\n",
    "                  (which is (2m choose 2)) \n",
    "        \"\"\"\n",
    "        B = x.size(0)\n",
    "\n",
    "        # 1) Average-pool down to (B, C, m, m)\n",
    "        x_pooled = self.pool(x)  # shape = (B, in_channels, m, m)\n",
    "\n",
    "        # 2) Flatten the pooled output to (B, in_channels * m * m)\n",
    "        x_im = x_pooled.view(B, -1)  # shape = (B, in_channels*m*m)\n",
    "\n",
    "        # For typical MNIST (C=1), x_im has shape (B, m*m).\n",
    "        # If C>1, then effectively we have C copies of (m*m) we can treat as separate channels \n",
    "        # for the \"IM basis.\" \n",
    "        # But let's keep it straightforward and just treat it as one long vector of length C*m*m.\n",
    "\n",
    "        # 3) Prepare output tensor in \"HW basis\" dimension = choose(2m,2)\n",
    "        x_hw = x_im.new_zeros(B, self.hw_dim)  # shape = (B, hw_dim)\n",
    "\n",
    "        # We'll define a helper for indexing the combination (a,b) where 0 <= a < b < 2m.\n",
    "        def comb_index(a, b, n=2*self.m):\n",
    "            \"\"\"\n",
    "            Map the pair (a,b) with a<b, a,b in [0..n-1]\n",
    "            into a unique index in [0..nC2-1].\n",
    "            nC2 = n*(n-1)/2.\n",
    "            \n",
    "            We'll use a known formula:\n",
    "              index = (2n - a - 1)*a/2 + (b - a - 1)\n",
    "            \"\"\"\n",
    "            return ( (2*n - a - 1)*a )//2 + (b - a - 1)\n",
    "\n",
    "        # 4) Fill in cross-side pairs.\n",
    "        #    - The left bits are [0..(m-1)]\n",
    "        #    - The right bits are [m..(2m-1)]\n",
    "        #\n",
    "        # If we treat (C*m*m) as \"C channels of an m x m patch,\" \n",
    "        # for each channel c in [0..C-1], \n",
    "        # for each row i in [0..m-1],\n",
    "        # for each col j in [0..m-1],\n",
    "        #   the amplitude is x_im[:, c*m*m + i*m + j].\n",
    "        #\n",
    "        # That amplitude goes into the HW-basis index comb_index(i, m+j).\n",
    "\n",
    "        # Number of channels we flattened = C\n",
    "        # Each channel has m*m entries.\n",
    "        # We'll map each (channel, i, j) triple to the appropriate index in HW basis.\n",
    "\n",
    "        total_entries_per_channel = self.m * self.m\n",
    "        for c in range(self.in_channels):\n",
    "            channel_offset = c*total_entries_per_channel\n",
    "            for i in range(self.m):\n",
    "                for j in range(self.m):\n",
    "                    a = i\n",
    "                    b = self.m + j\n",
    "                    idx = comb_index(a, b, 2*self.m)\n",
    "\n",
    "                    # The amplitude in x_im is at position [channel_offset + i*m + j]\n",
    "                    x_hw[:, idx] += x_im[:, channel_offset + i*self.m + j]\n",
    "\n",
    "        return x_hw\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-07T11:46:17.042956Z",
     "start_time": "2025-01-07T11:46:17.033274Z"
    }
   },
   "id": "f981dc3671bfe2c6"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MSE Loss: 0.062238410115242004\n",
      "Final MSE Loss: 0.04924457147717476\n",
      "Final MSE Loss: 0.06449488550424576\n",
      "Final MSE Loss: 0.06565090268850327\n",
      "Final MSE Loss: 0.06299500912427902\n",
      "Final MSE Loss: 0.07303983718156815\n",
      "Final MSE Loss: 0.04801149666309357\n",
      "Final MSE Loss: 0.045363735407590866\n",
      "Final MSE Loss: 0.049353133887052536\n",
      "Final MSE Loss: 0.07223477214574814\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from math import comb\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "############################################\n",
    "# 1) Perceval-related helper code (minimal)\n",
    "############################################\n",
    "def all_bitstrings_with_k_ones(n, k):\n",
    "    from itertools import combinations\n",
    "    bitstrings = []\n",
    "    for ones_positions in combinations(range(n), k):\n",
    "        bits = ['0'] * n\n",
    "        for pos in ones_positions:\n",
    "            bits[pos] = '1'\n",
    "        bitstrings.append(''.join(bits))\n",
    "    return bitstrings\n",
    "\n",
    "def state_str_to_bits(state_str):\n",
    "    bit_str_list = state_str.strip('|>').split(',')\n",
    "    return ''.join(bit_str_list)\n",
    "\n",
    "def distribution_to_vector(prob_dict, n, k):\n",
    "    bitstrings = all_bitstrings_with_k_ones(n, k)\n",
    "    idx_map = {bs: i for i, bs in enumerate(bitstrings)}\n",
    "    output_vec = [0]*len(bitstrings)\n",
    "    for k_str, v in prob_dict.items():\n",
    "        bs = state_str_to_bits(str(k_str))\n",
    "        if bs.count('1') == k and bs in idx_map:\n",
    "            output_vec[idx_map[bs]] = v\n",
    "    return output_vec\n",
    "\n",
    "def generate_perceval_circuit(m, gate_list, encode_angles, train_params):\n",
    "    \"\"\"\n",
    "    Minimal circuit builder:\n",
    "      * gate_list = list of (i, j) \n",
    "      * first len(encode_angles) parameters => encode portion\n",
    "      * next len(train_params) => training portion\n",
    "    \"\"\"\n",
    "    import perceval as pcvl\n",
    "    from perceval.components import BS, PERM\n",
    "\n",
    "    circuit = pcvl.Circuit(m)\n",
    "    param_index = 0\n",
    "\n",
    "    # Combine them for demonstration (encode + train gates).\n",
    "    # Or keep them separate if you prefer. We'll just do a single loop:\n",
    "    for (i, j) in gate_list:\n",
    "        # Possibly do some permutation\n",
    "        if i+1 != j:\n",
    "            n_ = abs(j - i)\n",
    "            permutation = [n_-1] + list(range(1, n_-1)) + [0]\n",
    "            circuit.add(i+1, PERM(permutation))\n",
    "\n",
    "        # Insert a parameterized BS\n",
    "        circuit.add(i, BS.H(theta=pcvl.P(f'phi_{param_index}')))\n",
    "        param_index += 1\n",
    "\n",
    "        if i+1 != j:\n",
    "            n_ = abs(j - i)\n",
    "            permutation = [n_-1] + list(range(1, n_-1)) + [0]\n",
    "            circuit.add(i+1, PERM(permutation))\n",
    "\n",
    "    # Set parameter values\n",
    "    params = circuit.get_parameters()\n",
    "    # encode portion\n",
    "    for i in range(len(encode_angles)):\n",
    "        params[i].set_value(encode_angles[i])\n",
    "    # train portion\n",
    "    start = len(encode_angles)\n",
    "    for i in range(len(train_params)):\n",
    "        params[start + i].set_value(train_params[i])\n",
    "\n",
    "    return circuit\n",
    "\n",
    "def run_perceval_circuit(m, n, circuit, input_state_list, postselect, samples):\n",
    "    \"\"\"\n",
    "    Return sqrt(prob) as (dim_state)-tensor\n",
    "    \"\"\"\n",
    "    import perceval as pcvl\n",
    "    proc = pcvl.Processor(\"SLOS\", m)\n",
    "    proc.set_circuit(circuit)\n",
    "    proc.min_detected_photons_filter(postselect)\n",
    "    proc.thresholded_output(True)\n",
    "    proc.with_input(pcvl.BasicState(input_state_list))\n",
    "\n",
    "    sampler = pcvl.algorithm.Sampler(proc, max_shots_per_call=samples)\n",
    "    res = sampler.probs(samples)\n",
    "    distribution = res[\"results\"]\n",
    "\n",
    "    vec = distribution_to_vector(distribution, m, n)\n",
    "    t = torch.tensor(vec, dtype=torch.float32)\n",
    "    return torch.sqrt(t)\n",
    "\n",
    "\n",
    "############################################\n",
    "# 2) Custom autograd with finite difference\n",
    "############################################\n",
    "class FiniteDiffFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, theta, m, n, gate_list, encode_angles, input_state_list, postselect, samples, eps):\n",
    "        \"\"\"\n",
    "        Returns (dim_state)-tensor from the circuit\n",
    "        \"\"\"\n",
    "        ctx.m = m\n",
    "        ctx.n = n\n",
    "        ctx.gate_list = gate_list\n",
    "        ctx.encode_angles = encode_angles\n",
    "        ctx.input_state_list = input_state_list\n",
    "        ctx.postselect = postselect\n",
    "        ctx.samples = samples\n",
    "        ctx.eps = eps\n",
    "        ctx.save_for_backward(theta)\n",
    "\n",
    "        # forward pass\n",
    "        circuit = generate_perceval_circuit(m, gate_list, encode_angles, theta.detach().cpu().numpy())\n",
    "        output = run_perceval_circuit(m, n, circuit, input_state_list, postselect, samples)\n",
    "        return output  # shape (comb(m, n),)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        (theta,) = ctx.saved_tensors\n",
    "        m = ctx.m\n",
    "        n = ctx.n\n",
    "        gate_list = ctx.gate_list\n",
    "        encode_angles = ctx.encode_angles\n",
    "        input_state_list = ctx.input_state_list\n",
    "        postselect = ctx.postselect\n",
    "        samples = ctx.samples\n",
    "        eps = ctx.eps\n",
    "\n",
    "        D = theta.shape[0]\n",
    "        grad_theta = torch.zeros_like(theta)\n",
    "        half = eps / 2.0\n",
    "\n",
    "        # For each param, do central difference\n",
    "        for i in range(D):\n",
    "            theta_plus = theta.clone()\n",
    "            theta_minus = theta.clone()\n",
    "            theta_plus[i] += half\n",
    "            theta_minus[i] -= half\n",
    "\n",
    "            circuit_plus = generate_perceval_circuit(m, gate_list, encode_angles, theta_plus.detach().cpu().numpy())\n",
    "            out_plus = run_perceval_circuit(m, n, circuit_plus, input_state_list, postselect, samples)\n",
    "\n",
    "            circuit_minus = generate_perceval_circuit(m, gate_list, encode_angles, theta_minus.detach().cpu().numpy())\n",
    "            out_minus = run_perceval_circuit(m, n, circuit_minus, input_state_list, postselect, samples)\n",
    "\n",
    "            diff = (out_plus - out_minus) / eps\n",
    "            grad_theta[i] = torch.dot(grad_output, diff)\n",
    "\n",
    "        return grad_theta, None, None, None, None, None, None, None, None\n",
    "\n",
    "\n",
    "class PercevalCircuitModule(nn.Module):\n",
    "    def __init__(self, m, n, gate_list, encode_angles, init_params,\n",
    "                 postselect, samples, eps=1e-4):\n",
    "        super().__init__()\n",
    "        self.theta = nn.Parameter(init_params.clone())\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.gate_list = gate_list\n",
    "        self.encode_angles = encode_angles\n",
    "        self.input_state_list = [1]*n + [0]*(m-n)\n",
    "        self.postselect = postselect\n",
    "        self.samples = samples\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self):\n",
    "        return FiniteDiffFunction.apply(\n",
    "            self.theta,\n",
    "            self.m, self.n,\n",
    "            self.gate_list,\n",
    "            self.encode_angles,\n",
    "            self.input_state_list,\n",
    "            self.postselect,\n",
    "            self.samples,\n",
    "            self.eps\n",
    "        )\n",
    "    \n",
    "    def set_encode_angles(self, encode_angles):\n",
    "        self.encode_angles = encode_angles\n",
    "\n",
    "m = 4\n",
    "n = 2\n",
    "postselect = n\n",
    "samples = 1\n",
    "dim_state = comb(m, n)\n",
    "batch_size = 1\n",
    "# A list of gates\n",
    "list_gates = [(i,j) for i in range(m) for j in range(m) if i<j]\n",
    "encode_angles = []\n",
    "init_params = torch.rand(len(list_gates), dtype=torch.float32)\n",
    "\n",
    "\n",
    "N = 10\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root=\".\", train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root=\".\", train=False, transform=transform, download=True)\n",
    "train_subset_indices = torch.arange(N)  # Select the first N indices\n",
    "train_dataset = Subset(train_dataset, train_subset_indices)\n",
    "test_subset_indices = torch.arange(N)  # Select the first N indices\n",
    "test_dataset = Subset(test_dataset, test_subset_indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "encoding_parameters = []\n",
    "for images, labels in train_loader:\n",
    "    model = PercevalCircuitModule(\n",
    "        m, n, list_gates,\n",
    "        encode_angles, init_params,\n",
    "        postselect=postselect,\n",
    "        samples=samples,\n",
    "        eps=1e-3  # smaller FD step => more accurate grads\n",
    "    )\n",
    "    # Let's define a small target distribution in 10D \n",
    "    # (random for demonstration).  We'll treat it as sqrt(prob).\n",
    "    # target_dist = torch.rand(dim_state)\n",
    "    # target_dist /= target_dist.sum()  # sum=1\n",
    "    # target_sqrt = torch.sqrt(target_dist.float())\n",
    "\n",
    "    # dummy_x = torch.randn(1, 1, 28, 28)\n",
    "    # Instantiate our encoder with m=10\n",
    "    encoder = Flexible_IM_to_HW_Encoder(input_size=28, m=m//2, in_channels=1)\n",
    "    # Forward-pass\n",
    "    out_hw = encoder(images)\n",
    "    target_sqrt = out_hw.squeeze()\n",
    "    # MSE Loss\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Use Adam\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-2)  # smaller LR\n",
    "\n",
    "    # We can do more iterations to let Adam converge\n",
    "    epochs = 1\n",
    "    steps_per_epoch = 50\n",
    "\n",
    "    for e in range(epochs):\n",
    "        for step in range(steps_per_epoch):\n",
    "            optimizer.zero_grad()\n",
    "            output = model()  # shape(10,)\n",
    "\n",
    "            loss = criterion(output, target_sqrt)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # if step % 10 == 0:\n",
    "            #     print(f\"Epoch={e+1}, Step={step}/{steps_per_epoch}, Loss={loss.item():.5f}\")\n",
    "\n",
    "    # Print final results\n",
    "    final_output = model().detach()\n",
    "    # final_output = final_output / final_output.sum()  # re-normalize to compare\n",
    "    target_sqrt_renorm = target_sqrt / target_sqrt.sum()\n",
    "\n",
    "    encoding_parameters.append(model.theta.data)\n",
    "    print(\"Final MSE Loss:\", criterion(final_output, target_sqrt_renorm).item())\n",
    "\n",
    "encode_angles = [torch.nn.Parameter(tensor, requires_grad=False) for tensor in encoding_parameters]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-07T14:20:28.757942Z",
     "start_time": "2025-01-07T14:20:01.278947Z"
    }
   },
   "id": "d2e251d90573729e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# second part\n",
    "Now we have encoding angles! We can start our training to MNIST labels:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "609ffe30594267fa"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.2751\n",
      "Accuracy: 10.00%\n",
      "Epoch [2/10], Loss: 2.2261\n",
      "Accuracy: 10.00%\n",
      "Epoch [3/10], Loss: 2.1808\n",
      "Accuracy: 10.00%\n",
      "Epoch [4/10], Loss: 2.1394\n",
      "Accuracy: 10.00%\n",
      "Epoch [5/10], Loss: 2.1018\n",
      "Accuracy: 20.00%\n",
      "Epoch [6/10], Loss: 2.0681\n",
      "Accuracy: 30.00%\n",
      "Epoch [7/10], Loss: 2.0379\n",
      "Accuracy: 30.00%\n",
      "Epoch [8/10], Loss: 2.0120\n",
      "Accuracy: 30.00%\n",
      "Epoch [9/10], Loss: 1.9903\n",
      "Accuracy: 30.00%\n",
      "Epoch [10/10], Loss: 1.9730\n",
      "Accuracy: 30.00%\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple network for MNIST. It:\n",
    "    1) Flattens the 28x28 input into a 784-dim vector\n",
    "    2) Feeds it to a hidden layer (fc1)\n",
    "    3) Passes it to Blackbox\n",
    "    4) Feeds the result to the final classification layer (fc2)\n",
    "    \"\"\"\n",
    "    def __init__(self, n, m, list_gates_encode, list_gates_train, encode_angles):\n",
    "        super(Net, self).__init__()\n",
    "        init_params = torch.rand(len(list_gates_train), dtype=torch.float32)\n",
    "        self.perceval_circuit = PercevalCircuitModule(\n",
    "            m, n, list_gates_encode + list_gates_train,\n",
    "            encode_angles, init_params,\n",
    "            postselect=postselect,\n",
    "            samples=samples,\n",
    "            eps=1e-3  # smaller FD step => more accurate grads\n",
    "        )\n",
    "        self.dense = nn.Linear((int)(comb(m,n)), 10)\n",
    "\n",
    "    def forward(self):\n",
    "        # Flatten the input from (B, 1, 28, 28) -> (B, 784)\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = self.perceval_circuit()  # Apply Blackbox to the hidden representation\n",
    "        x = self.dense(x)\n",
    "        return x.unsqueeze(0)\n",
    "    \n",
    "    def set_encode_angles(self, encode_angles):\n",
    "        # self.perceval_circuit.encode_angles = encode_angles\n",
    "        self.perceval_circuit.set_encode_angles(encode_angles)\n",
    "        \n",
    "\n",
    "list_gates_encode = [(i,j) for i in range(m) for j in range(m) if i<j]\n",
    "list_gates_train = [(i,j) for i in range(m) for j in range(m) if i<j]\n",
    "\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "model = Net(n, m, list_gates_encode, list_gates_train, [])\n",
    "for e in range(epochs):\n",
    "    index = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        model.perceval_circuit.encode_angles = encode_angles[index]\n",
    "        # print(model.perceval_circuit.encode_angles.requires_grad)\n",
    "        # print(model.perceval_circuit.theta.requires_grad)\n",
    "        index += 1\n",
    "        # MSE Loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        target = labels\n",
    "        # Use Adam\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-2)  # smaller LR\n",
    "        # We can do more iterations to let Adam converge\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        output = model()  # shape(10,)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(labels.shape)\n",
    "        # print(predicted.shape)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    if e%1 == 0:\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{e+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
    "        print(f\"Accuracy: {100.0 * correct / total:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-07T14:24:12.474831Z",
     "start_time": "2025-01-07T14:24:04.242025Z"
    }
   },
   "id": "dfd8d4a9878e2282"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
